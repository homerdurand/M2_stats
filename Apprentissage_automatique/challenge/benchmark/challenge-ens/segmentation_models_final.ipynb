{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#!pip install tifffile\n",
    "#!pip install scikit-image\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from tifffile import TiffFile\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from framework.dataset_modified import LandCoverData as LCD\n",
    "from framework.dataset_modified import parse_image, load_image_train, load_image_test, numpy_parse_image\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread\n",
    "\n",
    "from weighted_loss import loss as weighted_categorical_cross_entropy\n",
    "from PIL import Image\n",
    "\n",
    "import segmentation_models as sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER_STR = '/home/homer/Documents/Master_Statistique/Apprentissage_automatique/challenge/benchmark/challenge-ens/data'\n",
    "DATA_FOLDER = Path(DATA_FOLDER_STR).expanduser()\n",
    "# path to the unzipped dataset: contains directories train/ and test/\n",
    "DATASET_FOLDER = DATA_FOLDER/'dataset'\n",
    "\n",
    "# get all train images and masks\n",
    "train_images_paths = sorted(list(DATASET_FOLDER.glob('train/images/*.tif')))\n",
    "train_masks_paths = sorted(list(DATASET_FOLDER.glob('train/masks/*.tif')))\n",
    "# get all test images\n",
    "test_images_paths = sorted(list(DATASET_FOLDER.glob('test/images/*.tif')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_mask(image_path) :\n",
    "    mask_path = image_path.parent.parent/'masks'/image_path.name\n",
    "    with TiffFile(image_path) as tifi, TiffFile(mask_path) as tifm:\n",
    "        image = tifi.asarray()\n",
    "        mask = tifm.asarray()\n",
    "        # add channel dimension to mask: (256, 256, 1)\n",
    "        mask = mask[..., None]\n",
    "    return image, mask\n",
    "\n",
    "def compute_distribution(mask) :\n",
    "    count = np.bincount(mask.ravel(), minlength=10)\n",
    "    distrib = count/sum(count)\n",
    "    return np.array(distrib)\n",
    "\n",
    "def load_distributions(paths, n_max=1000) :\n",
    "    ditributions = []\n",
    "    for path in tqdm(paths):\n",
    "        _, mask = load_image_mask(path)\n",
    "        distrib = compute_distribution(mask)\n",
    "        ditributions.append(distrib)\n",
    "    return np.array(ditributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_filenames_test = np.array([DATA_FOLDER_STR + '/dataset/test/images/' + path.name for path in test_images_paths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18491/18491 [01:06<00:00, 278.96it/s]\n"
     ]
    }
   ],
   "source": [
    "labels = load_distributions(train_images_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filenames, val_filenames, train_labels, val_labels = train_test_split(train_images_paths, labels, test_size=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKBONE = 'mobilenetv2'\n",
    "preprocess_input = sm.get_preprocessing(BACKBONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_Custom_Generator(tf.keras.utils.Sequence) :\n",
    "  \n",
    "    def __init__(self, image_filenames, batch_size) :\n",
    "        self.image_filenames = image_filenames\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    \n",
    "    def __len__(self) :\n",
    "        return (np.ceil(len(self.image_filenames) / float(self.batch_size))).astype(np.int)\n",
    "  \n",
    "  \n",
    "    def __getitem__(self, idx) :\n",
    "        batch_x = self.image_filenames[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "        return np.array([preprocess_input(self.load_image(file_name)) for file_name in batch_x])/255.0, np.array([tf.one_hot(self.load_mask(file_name), 10) for file_name in batch_x])\n",
    "    \n",
    "    def load_image(self, image_path, channels=4) :\n",
    "        mask_path = image_path.parent.parent/'masks'/image_path.name\n",
    "        with TiffFile(image_path) as tifi :\n",
    "            image = tifi.asarray()[:,:,:channels]\n",
    "        return image\n",
    "    \n",
    "    def load_mask(self, image_path):\n",
    "        mask_path = image_path.parent.parent/'masks'/image_path.name\n",
    "        with TiffFile(mask_path) as tifm :\n",
    "            mask = tifm.asarray()\n",
    "        return mask\n",
    "    \n",
    "class My_Custom_Generator_test(tf.keras.utils.Sequence) :\n",
    "  \n",
    "    def __init__(self, image_filenames, batch_size) :\n",
    "        self.image_filenames = image_filenames\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    \n",
    "    def __len__(self) :\n",
    "        return (np.ceil(len(self.image_filenames) / float(self.batch_size))).astype(np.int)\n",
    "  \n",
    "  \n",
    "    def __getitem__(self, idx) :\n",
    "        batch_x = self.image_filenames[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "        return np.array([preprocess_input(self.load_image(file_name)) for file_name in batch_x])/255.0\n",
    "    \n",
    "    def load_image(self, image_path, channels=4) :\n",
    "        with TiffFile(image_path) as tifi :\n",
    "            image = tifi.asarray()[:,:,:channels]\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=4\n",
    "train_generator = My_Custom_Generator(train_filenames, batch_size)\n",
    "val_generator = My_Custom_Generator(val_filenames, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "valtest_gen = My_Custom_Generator_test(val_filenames, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = My_Custom_Generator_test(image_filenames_test, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 256, 256, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = train_generator.__getitem__(0)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, None, None, 4)]   0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, None, None, 3)     15        \n",
      "_________________________________________________________________\n",
      "model_4 (Functional)         (None, None, None, 10)    4145882   \n",
      "=================================================================\n",
      "Total params: 4,145,897\n",
      "Trainable params: 1,917,689\n",
      "Non-trainable params: 2,228,208\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sm.set_framework('tf.keras')\n",
    "sm.framework()\n",
    "\n",
    "base_model = sm.Linknet(BACKBONE, encoder_weights='imagenet', classes=10, encoder_freeze=True, activation='softmax')\n",
    "\n",
    "inp = tf.keras.layers.Input(shape=(None, None, 4))\n",
    "l1 = tf.keras.layers.Conv2D(3, (1, 1))(inp)\n",
    "out = base_model(l1)\n",
    "\n",
    "model = tf.keras.models.Model(inp, out, name=base_model.name)\n",
    "model.summary()\n",
    "\n",
    "loss = sm.losses.categorical_focal_loss + sm.losses.jaccard_loss\n",
    "model.compile(\n",
    "    'Adam',\n",
    "    loss=loss,\n",
    "    metrics=[sm.metrics.iou_score, 'accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "4576/4576 [==============================] - 8534s 2s/step - loss: 0.7212 - iou_score: 0.3023 - accuracy: 0.7073 - val_loss: 0.8105 - val_iou_score: 0.2199 - val_accuracy: 0.6341\n",
      "Epoch 2/30\n",
      "1943/4576 [===========>..................] - ETA: 1:38:11 - loss: 0.4155 - iou_score: 0.6065 - accuracy: 0.7504"
     ]
    }
   ],
   "source": [
    "hist = model.fit_generator(generator=train_generator,\n",
    "                   steps_per_epoch = int(len(train_filenames) // batch_size),\n",
    "                   epochs = 30,\n",
    "                   verbose = 1,\n",
    "                   validation_data = val_generator,\n",
    "                   validation_steps = int(len(val_filenames) // batch_size),\n",
    "                   #class_weight = class_weight\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Epoch 1** : En envrion 40 min on a : \n",
    "   * *train* $\\rightarrow$ accuracy=0.6527, loss=0.8324\n",
    "   * *test* $\\rightarrow$ accuracy=0.65, loss=0.8330"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_as_vectors(model, dataset, steps=None):\n",
    "    \"\"\"Perform a forward pass over the dataset and bincount the prediction masks to return class vectors.\n",
    "    Args:\n",
    "        model (tf.keras.Model): model\n",
    "        dataset (tf.data.Dataset): dataset to perform inference on\n",
    "        steps (int, optional): the total number of steps (batches) in the dataset, used for the progress bar\n",
    "    Returns:\n",
    "        (pandas.DataFrame): predicted class distribution vectors for the dataset\n",
    "    \"\"\"\n",
    "    def bincount_along_axis(arr, minlength=None, axis=-1):\n",
    "        \"\"\"Bincounts a tensor along an axis\"\"\"\n",
    "        if minlength is None:\n",
    "            minlength = tf.reduce_max(arr) + 1\n",
    "        mask = tf.equal(arr[..., None], tf.range(minlength, dtype=arr.dtype))\n",
    "        return tf.math.count_nonzero(mask, axis=axis-1 if axis < 0 else axis)\n",
    "\n",
    "    predictions = []\n",
    "    for batch in tqdm(dataset, total=steps):\n",
    "        # predict a raster for each sample in the batch\n",
    "        pred_raster = model.predict_on_batch(batch)\n",
    "\n",
    "        (batch_size, _, _, num_classes) = tuple(pred_raster.shape)\n",
    "        pred_mask = tf.argmax(pred_raster, -1) # (bs, 256, 256)\n",
    "        # bincount for each sample\n",
    "        counts = bincount_along_axis(\n",
    "            tf.reshape(pred_mask, (batch_size, -1)), minlength=num_classes, axis=-1\n",
    "        )\n",
    "        predictions.append(counts / tf.math.reduce_sum(counts, -1, keepdims=True))\n",
    "\n",
    "    predictions = tf.concat(predictions, 0)\n",
    "    return predictions.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1850/1850 [03:18<00:00,  9.30it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = predict_as_vectors(model, valtest_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_metric_5SF9GKS import custom_metric_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05893625727418147"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "custom_metric_function(pd.DataFrame(predictions), pd.DataFrame(val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5043/5043 [08:46<00:00,  9.58it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions_test = predict_as_vectors(model, test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(predictions_test, columns=['no_data', 'clouds','artificial','cultivated','broadleaf','coniferous','herbaceous','natural','snow','water'])\n",
    "df.to_csv('results/linknet/result2_dropout_mvnetfreezed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
